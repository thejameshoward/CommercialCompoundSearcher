{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommercialCompoundSearcher\n",
    "An internal Sigman Lab tool for assessing the commercial availability of molecules based on the Pubchem database. We highly recommended to begin with a small subset (~25 molecules) to test the script first before using it on a larger dataset. Once a few variables are defined in later cells (like vendors to ignore), the script can be run autonomously by running all cells.\n",
    "\n",
    "\n",
    "[https://github.com/thejameshoward/CommercialCompoundSearcher](https://github.com/thejameshoward/CommercialCompoundSearcher)\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built ins\n",
    "import urllib\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Custom\n",
    "from utils import canonicalize_smiles, smiles_to_inchi_key, smiles_to_inchi\n",
    "from utils import remove_duplicate_inchi_keys\n",
    "from utils import get_cid_from_inchi_key, get_vendor_list_from_cid\n",
    "from utils import remove_specific_vendors_from_dataframe\n",
    "from utils import draw_molecules_to_grid_image\n",
    "from utils import convert_str_list\n",
    "from utils import get_CAS_from_cid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in list of smiles\n",
    "\n",
    "The list of smiles can be a plaintext document with __SMILES__ in the first line and the '.txt' extension. Alternatively, the file extension could be '.csv' and also contain a __SMILES__ column.\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ SMILES                 ‚îÇ\n",
    "‚îÇ CC(=O)OCC[N+](C)(C)C   ‚îÇ\n",
    "‚îÇ CC(C[N+](C)(C)C)OC(=O) ‚îÇ\n",
    "‚îÇ ...                    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a file\n",
    "file = Path('./data/small.txt')\n",
    "\n",
    "# Read in the file\n",
    "if file.suffix == '.txt':\n",
    "    df = pd.read_table(file, header=0)\n",
    "elif file.suffix == '.csv':\n",
    "    df = pd.read_csv(file, header=0)\n",
    "else:\n",
    "    raise ValueError(f'{file.name} does not have a supported extension.')\n",
    "\n",
    "# Check that the file is formatted correctly\n",
    "assert 'SMILES' in df.columns\n",
    "\n",
    "# Drop any empty rows\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonicalization and additional molecular identifiers\n",
    "\n",
    "This section is used to canonicalize the SMILES and add additional molecular identifier information using RDKit. The output of this block will contain warnings (and potentially errors) from RDKit. Many of these errors (such as None mol from RDKit) are handled by removing the SMILES string and storing it in a separate file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply canonicalization\n",
    "#TODO Understand how this affects stereoisomerism in the SMILES/InChI/InChI key values\n",
    "df['SMILES'] = df['SMILES'].apply(canonicalize_smiles)\n",
    "\n",
    "# Add InChI column\n",
    "df['INCHI'] = df['SMILES'].apply(smiles_to_inchi)\n",
    "\n",
    "# Add InChI key column\n",
    "df['INCHI_KEY'] = df['SMILES'].apply(smiles_to_inchi_key)\n",
    "\n",
    "# Get every row that has np.nan values\n",
    "failed = df[(df['INCHI'].isna()) | (df['INCHI_KEY'].isna())]\n",
    "\n",
    "# Get every row that does not have np.nan values\n",
    "df = df[~(df['INCHI'].isna()) | ~(df['INCHI_KEY'].isna())].copy(deep=True)\n",
    "\n",
    "# Save the failed and the canonicalized datasets to a csv file\n",
    "failed.to_csv('./results/failed_canonicalization.csv', index=False)\n",
    "df.to_csv('./results/canonicalized.csv', index=False)\n",
    "\n",
    "# Check if anything failed an notify the user\n",
    "if failed.empty:\n",
    "    print('No SMILES strings failed canonicalization.')\n",
    "else:\n",
    "    display(failed)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate InChI keys\n",
    "\n",
    "Because we will be using REST queries to gather vendor information, it is important to remove duplicates because they will \"waste\" and REST query. This procedure removes __exact__ duplicates of the InChI key in the dataframe even if the SMILES string is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicates\n",
    "df, duplicates = remove_duplicate_inchi_keys(df=df)\n",
    "\n",
    "# For your viewing pleasure\n",
    "display(df)\n",
    "\n",
    "if duplicates.empty:\n",
    "    print('No duplicate entries were found.')\n",
    "else:\n",
    "    display(duplicates)\n",
    "\n",
    "# Save the results for good book keeping.\n",
    "df.to_csv('./results/added_molecular_identifiers.csv', index=False)\n",
    "duplicates.to_csv('./results/duplicate_molecular_identifiers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Pubchem for CID\n",
    "\n",
    "The best identifier to use for querying Pubchem is the Pubchem Compound ID (CID). For more information on how Pubchem standardizes its database, please see the [compounds webpage](https://pubchem.ncbi.nlm.nih.gov/docs/compounds). This section will obtain a CID for a given InChi key. The REST queries each take at least 200 ms.\n",
    "\n",
    "__If you stop this cell while it is running, you will lose all of your progress__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get inchi keys as a list\n",
    "inchi_keys = df['INCHI_KEY'].to_list()\n",
    "\n",
    "# This assertion statement will fail if you have duplicate \n",
    "# InChi keys. If you don't care, remove the following line\n",
    "assert len(list(set(inchi_keys))) == df.shape[0]\n",
    "\n",
    "# Get the total length of InChI keys for tracking progress\n",
    "total = len(inchi_keys)\n",
    "\n",
    "# Enumerate over all inchi keys and add CID values\n",
    "for i, inchi_key in enumerate(inchi_keys):\n",
    "\n",
    "    print(f'Working on {i + 1} of {total} ({round((i + 1) / total * 100, 2)}%)')\n",
    "\n",
    "    # Set cid to nan if we can't find it\n",
    "    cid = np.nan\n",
    "\n",
    "    # Try to get the CID, if there is no CID, skip\n",
    "    try:\n",
    "        cid = get_cid_from_inchi_key(inchi_key)\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(f'Could not convert InChi Key {inchi_key} to CID because {e}. Skipping.')\n",
    "        continue\n",
    "\n",
    "    # Check how many instances of that INCHI_KEY are in the df\n",
    "    if df[df['INCHI_KEY'] == inchi_key].shape[0] != 1:\n",
    "        print(f'WARNING: Found more than one InChI key {inchi_key}!')\n",
    "\n",
    "    # Add the CID based on inchi_key\n",
    "    df.loc[df['INCHI_KEY'] == inchi_key, 'CID'] = str(cid)\n",
    "\n",
    "# Get the df of molecules for which there is no CID, save it for good book keeping\n",
    "no_cids = df[df['CID'].astype(float).isna()]\n",
    "no_cids.to_csv('./results/no_cid_found.csv', index=False)\n",
    "\n",
    "# Get the new df that has CID values for each molecule\n",
    "df = df[~(df['CID'].astype(float).isna())].copy(deep=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Pubchem for vendors\n",
    "\n",
    "This section will us the CID values found in the previous cell to acquire a list of vendors from Pubchem. The REST queries each take at least 200 ms.\n",
    "\n",
    "__If you stop this cell while it is running, you will lose all of your progress towards acquiring vendors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get inchi keys as a list\n",
    "cids = df['CID'].astype(int).to_list()\n",
    "\n",
    "# This assertion statement will fail if you have duplicate \n",
    "# InChi keys. If you don't care, remove the following line\n",
    "assert len(list(set(cids))) == df.shape[0]\n",
    "\n",
    "# Get the total number of CIDs for tracking progress\n",
    "total = len(cids)\n",
    "\n",
    "# Keep a list of CIDs that have no vendors\n",
    "no_vendor_cids = []\n",
    "\n",
    "# Make a CID vendor dictionary that will contain the\n",
    "# PubchemVendor objects\n",
    "cid_vendor_dict = {}\n",
    "\n",
    "# Enumerate over all CIDs and look for vendors\n",
    "for i, cid in enumerate(cids):\n",
    "    print(f'Working on {i + 1} of {total} ({round((i + 1) / total * 100, 2)}%)')\n",
    "\n",
    "    # Try to get the list of PubchemVendor objects\n",
    "    try:\n",
    "        vendors = list(set(get_vendor_list_from_cid(cid)))\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(f'Could not get vendor list from CID {cid}.')\n",
    "        no_vendor_cids.append(int(cid))\n",
    "        continue\n",
    "\n",
    "    # Check how many instances of that CID are in the df\n",
    "    if df[df['CID'].astype(int) == cid].shape[0] != 1:\n",
    "        print(f'WARNING: Found more than one CID for {cid}!')\n",
    "\n",
    "    # Add the CID/VENDORS based on inchi_key\n",
    "    df.loc[df['CID'].astype(int) == cid, 'VENDORS'] = str([x.SourceName for x in vendors])\n",
    "\n",
    "    # Add the CID:Vendor key:value pair\n",
    "    cid_vendor_dict[cid] = vendors\n",
    "\n",
    "# Get the df of molecules for which there are no vendors, save it for good book keeping\n",
    "no_vendors = df[df['CID'].astype(int).isin(no_vendor_cids)].copy(deep=True)\n",
    "no_vendors.to_csv('./results/no_vendors_found.csv')\n",
    "\n",
    "# Get all the molecules that have vendors\n",
    "df = df[~df['CID'].astype(int).isin(no_vendor_cids)]\n",
    "\n",
    "display(df)\n",
    "\n",
    "#print(cid_vendor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Vendors\n",
    "\n",
    "The term \"commercial availability\" may differ between applications. Some vendors report that a compound is purchasable but will only synthesize it upon request. Additionally, the geographic location of the vendor's warehouse may lead to extended shipping times. In this section, we can filter vendors by selecting them from a list of total vendors.\n",
    "\n",
    "The next cells are organized into separate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total list of vendors\n",
    "list_of_current_vendors = list(set([vendor for vendor_list in df['VENDORS'].apply(convert_str_list) for vendor in vendor_list]))\n",
    "display(f'UNIQUE VENDORS:')\n",
    "pprint(list_of_current_vendors)\n",
    "print(f'\\nN_UNIQUE_VENDORS: {len(list_of_current_vendors)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select vendors to keep __OR__ vendors to remove\n",
    "\n",
    "Two variables are declared below. Define one and only one of these variables to be a list of vendor strings. __This section relies on exact string comparison. Thus, it is important that the **exact** string is used from the block above.__ We recommend using VENDORS_TO_REMOVE to be more deliberate with vendor selection.\n",
    "\n",
    "(experimental) We've included a list of vendors as a template for VENDORS_TO_KEEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define only one of these as a list\n",
    "VENDORS_TO_KEEP = ['TCI (Tokyo Chemical Industry)',\n",
    " 'Ambeed',\n",
    " 'Combi-Blocks',\n",
    " 'Thermo Fisher Scientific',\n",
    " 'Sigma-Aldrich',\n",
    " 'VWR, Part of Avantor']\n",
    "\n",
    "VENDORS_TO_REMOVE = None\n",
    "\n",
    "# Convert the string representation of the list of vendors\n",
    "# to an actual Python list\n",
    "df['VENDORS'] = df['VENDORS'].apply(convert_str_list)\n",
    "\n",
    "# Get the list of current vendors (again)\n",
    "list_of_current_vendors = list(set([vendor for vendor_list in df['VENDORS'].apply(convert_str_list) for vendor in vendor_list]))\n",
    "\n",
    "# Convert vendors to keep into a vendors_to_remove list\n",
    "if VENDORS_TO_REMOVE is None and VENDORS_TO_KEEP is not None:\n",
    "    VENDORS_TO_REMOVE = [x for x in list_of_current_vendors if x not in VENDORS_TO_KEEP]\n",
    "\n",
    "# Illegal options\n",
    "elif VENDORS_TO_REMOVE is not None and VENDORS_TO_KEEP is not None:\n",
    "    raise ValueError(f'Define either VENDORS_TO_REMOVE or VENDORS_TO_KEEP as a list not both.')\n",
    "\n",
    "# User not removing any vendors\n",
    "elif VENDORS_TO_REMOVE is None and VENDORS_TO_KEEP is None:\n",
    "    VENDORS_TO_REMOVE = []\n",
    "\n",
    "else:\n",
    "    raise ValueError(f'Make sure you define the unused variable at the beginning of this cell to None')\n",
    "\n",
    "# Remove the unwanted vendors\n",
    "df = remove_specific_vendors_from_dataframe(df, vendors=VENDORS_TO_REMOVE)\n",
    "\n",
    "# Purge empty df entries now\n",
    "#TODO Reevaluate use of string literals as list intermediates\n",
    "df = df[~(df['VENDORS'].astype(str) == '[]')]\n",
    "\n",
    "display(df)\n",
    "\n",
    "\n",
    "'''\n",
    "# TODO Get the links from the vendor information from pubchem\n",
    "# Get the new list of vendors\n",
    "list_of_current_vendors = list(set([vendor for vendor_list in df['VENDORS'].to_list() for vendor in vendor_list]))\n",
    "print(f'UNIQUE VENDORS:')\n",
    "pprint(list_of_current_vendors)\n",
    "print(f'\\nN_UNIQUE_VENDORS: {len(list_of_current_vendors)}')\n",
    "\n",
    "display(df)\n",
    "\n",
    "for col in df.columns:\n",
    "    print(df[col].dtype)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the curated list of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./FINAL_LIBRARY_CURATED.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Pubchem for CAS number\n",
    "\n",
    "This section will us the CID values found in the previous cells to acquire a CAS number from Pubchem. Often a molecule will have multiple CAS numbers and the `get_CAS_from_CID()` function will gather only one of them. Users should be aware that this looks for two dashes (-) in the numbers it receives from Pubchem to identify the CAS number. This procedure could be improved by a more systematic way of determining whether the item received from Pubchem is actually a CAS number. The REST queries each take at least 200 ms.\n",
    "\n",
    "__If you stop this cell while it is running, you will lose all of your progress towards acquiring vendors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full list of CIDs from the library\n",
    "cids = [int(x) for x in df['CID'].to_list() if x != '']\n",
    "\n",
    "# Get the total number of CIDs for tracking progress\n",
    "total = len(cids)\n",
    "\n",
    "# Keep a list of CIDs that have no vendors\n",
    "no_vendor_cids = []\n",
    "\n",
    "# Enumerate over all CIDs and look for vendors\n",
    "for i, cid in enumerate(cids):\n",
    "    print(f'Working on {i + 1} of {total} ({round((i + 1) / total * 100, 2)}%)')\n",
    "\n",
    "    # Try to get the list of PubchemVendor objects\n",
    "    try:\n",
    "        cas = get_CAS_from_cid(cid)\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(f'Could not get CAS number from CID {cid}. ERROR: {e}')\n",
    "        continue\n",
    "\n",
    "    # Add the CID/VENDORS based on inchi_key\n",
    "    df.loc[df['CID'].astype(int) == cid, 'CAS_NUMBER'] = str(cas)\n",
    "\n",
    "    # Check how many instances of that CID are in the df\n",
    "    #if df[df['CID'].astype(int) == cid].shape[0] != 1:\n",
    "    #    print(df[df['CID'] == cid])\n",
    "    #    print(f'WARNING: Found more than one CID for {cid}!')\n",
    "    ## Add the CID/VENDORS based on inchi_key\n",
    "    #df.loc[df['CID'].astype(int) == cid, 'CAS'] = str(cas)\n",
    "\n",
    "# Save the file \n",
    "df.to_csv('./FINAL_LIBRARY_CURATED_with_cas_numbers.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query a Sigman Inventory Export for the CAS numbers\n",
    "\n",
    "Export a full copy of the Sigman inventory in labsuit and point the inventory_spreadsheet variable to its path. This cell will create a slice of the dataframe that contains CAS numbers in both your curated library and the inventory spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the spreadsheet file\n",
    "inventory_spreadsheet = Path('./data/Sigman-inventory-03-07-2024-example.xlsx')\n",
    "\n",
    "# Read in the file (These settings should read the default format)\n",
    "try:        \n",
    "    inventory = pd.read_excel(file, header=0, sheet_name='Chemical', engine='openpyxl')\n",
    "except Exception: # This is required because I think labsuit is not zipping their xlsx files\n",
    "    with open(inventory_spreadsheet, 'rb') as infile:\n",
    "        inventory = pd.read_excel(infile, sheet_name='Chemical')\n",
    "\n",
    "# Filter inventory by presence of CAS\n",
    "inventory['CAS_NUMBER'] = inventory['CAS_NUMBER'].astype(str).apply(str.strip)\n",
    "inventory = inventory[inventory['CAS_NUMBER'].astype(str).isin(df['CAS_NUMBER'])]\n",
    "\n",
    "display(inventory)\n",
    "\n",
    "# Save the owned molecules in the results folder\n",
    "inventory.to_csv('./results/owned_molecules.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing molecules ü•≥ !\n",
    "\n",
    "In this section we've included some useful functions for drawing molecules in your library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all smiles\n",
    "smiles = df['SMILES'].to_list()\n",
    "\n",
    "print(f'Number of SMILES: {len(smiles)}')\n",
    "\n",
    "# Get the PIL images of the grid by passing smiles list\n",
    "images = draw_molecules_to_grid_image(smiles, mols_per_row=6, img_resolution=600)\n",
    "\n",
    "for image in images:\n",
    "    display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "commercialSearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
